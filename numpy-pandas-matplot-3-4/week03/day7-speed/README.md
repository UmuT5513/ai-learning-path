# ğŸ“Š CSV Okuma YÃ¶ntemleri: HÄ±z ve Bellek KarÅŸÄ±laÅŸtÄ±rmasÄ±

Bu mini projede yaklaÅŸÄ±k 50 MB bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir CSV dosyasÄ±nÄ± Ã¼Ã§ farklÄ± yÃ¶ntemle okuyarak **sÃ¼re** ve **RAM kullanÄ±mÄ±** aÃ§Ä±sÄ±ndan karÅŸÄ±laÅŸtÄ±rdÄ±m.

---

## ğŸ¯ AmaÃ§

- Pandas ile bÃ¼yÃ¼k dosyalarÄ± okurken performans farklarÄ±nÄ± gÃ¶rmek
- AÅŸaÄŸÄ±daki yÃ¶ntemleri karÅŸÄ±laÅŸtÄ±rmak:
  1. `pd.read_csv()` (standart yÃ¶ntem)
  2. `pd.read_csv()` + `chunksize` (parÃ§a parÃ§a okuma)
  3. `pd.read_csv()` + `engine='pyarrow'` (hÄ±zlÄ± C tabanlÄ± okuma)

---

## âš™ï¸ Kurulum

```bash
pip install pandas pyarrow psutil matplotlib seaborn



| YÃ¶ntem    | SÃ¼re (s) | RAM KullanÄ±mÄ± (MB) | SatÄ±r SayÄ±sÄ± |
| --------- | -------- | ------------------ | ------------ |
| Standard  | 0.549     | 62.863              | 2,000,000    |
| Chunksize | 0.569     | 59.980               | 2,000,000    |
| PyArrow   | 0.115     | 251.895               | 2,000,000    |


â„¹ï¸ GerÃ§ek deÄŸerler bilgisayar sistemine gÃ¶re deÄŸiÅŸebilir.